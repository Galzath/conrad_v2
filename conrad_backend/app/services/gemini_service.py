import google.generativeai as genai
from ..core.config import settings
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GeminiService:
    def __init__(self):
        try:
            if not settings.GEMINI_API_KEY or "YOUR_GEMINI_API_KEY" in settings.GEMINI_API_KEY:
                logger.error("Gemini API Key not configured. Please set it in .env or environment variables.")
                self.model = None
                raise ValueError("Gemini API Key not configured.")

            genai.configure(api_key=settings.GEMINI_API_KEY)
            # Initialize the GenerativeModel - specify the model name, e.g., 'gemini-pro'
            # For text-only input, use 'gemini-pro'
            # For text-and-image input, use 'gemini-pro-vision'
            self.model = genai.GenerativeModel('gemini-1.5-flash-latest')
            logger.info("Successfully configured Gemini API and initialized the model.")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini Service: {e}")
            self.model = None

    def generate_response(self, user_question: str, confluence_context: str) -> str:
        if not self.model:
            logger.error("Gemini model not initialized. Cannot generate response.")
            return "Error: The AI model is currently unavailable. Please try again later."

        prompt = f"""
Eres Conrad, un asistente virtual experto en la base de conocimientos de nuestra empresa almacenada en Confluence.
Un usuario ha preguntado: "{user_question}"

Basándote EXCLUSIVAMENTE en la siguiente información extraída de Confluence, por favor proporciona una respuesta clara y concisa.
Si la información no es suficiente para responder, indícalo amablemente.

Contexto de Confluence:
{confluence_context}

Respuesta:
"""

        logger.info(f"Sending prompt to Gemini: {prompt[:200]}...") # Log first 200 chars of prompt

        try:
            # Generation configuration (optional, for more control)
            # generation_config = genai.types.GenerationConfig(
            #     candidate_count=1,
            #     stop_sequences=['...'], # Example stop sequence
            #     max_output_tokens=1024,
            #     temperature=0.7,
            #     top_p=0.9,
            #     top_k=40
            # )
            # response = self.model.generate_content(prompt, generation_config=generation_config)

            response = self.model.generate_content(prompt)

            if response and response.parts:
                # Accessing text from the first part, assuming it's a simple text response
                # For more complex scenarios, you might need to iterate through parts
                # or check part types (e.g., if function calls are enabled).
                generated_text = "".join(part.text for part in response.parts if hasattr(part, 'text'))
                logger.info("Successfully received response from Gemini.")
                return generated_text if generated_text else "No response text found."
            elif response and response.prompt_feedback:
                 # Handle cases where the prompt was blocked
                logger.warning(f"Gemini API call did not return content. Prompt Feedback: {response.prompt_feedback}")
                return f"Error: The request was blocked by the AI for the following reason: {response.prompt_feedback}"
            else:
                logger.warning("Gemini API call did not return any content or parts.")
                return "Error: No response was generated by the AI model."

        except Exception as e:
            logger.error(f"Error during Gemini API call: {e}")
            # Specific check for blocked prompts if the exception has response attribute
            if hasattr(e, 'response') and e.response:
                 logger.error(f"Gemini API Error Response: {e.response}")
            return "Error: An unexpected issue occurred while trying to communicate with the AI model."

# Example Usage (for testing purposes)
if __name__ == "__main__":
    # This part requires .env to be correctly set up in the parent directory
    # or environment variables to be available.
    # You might need to adjust path for config if running this file directly.
    # from conrad_backend.app.core.config import settings # Adjust import if necessary

    if not settings.GEMINI_API_KEY or "YOUR_GEMINI_API_KEY" in settings.GEMINI_API_KEY:
        print("Gemini API key not configured. Please set it in .env")
    else:
        gemini_service = GeminiService()
        if gemini_service.model:
            test_question = "¿Cómo creo una página en Confluence?"
            test_context = "Para crear una página en Confluence, ve al espacio deseado, haz clic en el botón 'Crear' en la parte superior y selecciona 'Página'. Luego, puedes añadir un título y contenido."

            print(f"Testing Gemini with question: {test_question}")
            answer = gemini_service.generate_response(test_question, test_context)
            print(f"Gemini's Answer:\n{answer}")

            print("\nTesting Gemini with insufficient context:")
            test_question_insufficient = "¿Cuál es el presupuesto de marketing para Q3?"
            test_context_insufficient = "Confluence tiene información sobre proyectos y documentación técnica."
            answer_insufficient = gemini_service.generate_response(test_question_insufficient, test_context_insufficient)
            print(f"Gemini's Answer (insufficient context):\n{answer_insufficient}")
        else:
            print("Could not initialize GeminiService.")
