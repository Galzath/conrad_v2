import google.generativeai as genai
from ..core.config import settings
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GeminiService:
    def __init__(self):
        try:
            if not settings.GEMINI_API_KEY or "YOUR_GEMINI_API_KEY" in settings.GEMINI_API_KEY:
                logger.error("Gemini API Key not configured. Please set it in .env or environment variables.")
                self.model = None
                raise ValueError("Gemini API Key not configured.")

            genai.configure(api_key=settings.GEMINI_API_KEY)

            # Set the model permanently based on user selection from the list.
            # The previous step (listing models) used 'gemini-1.5-flash-latest' as the trial model
            # after the list was printed. User confirms this choice.
            model_name_to_use = 'gemini-1.5-flash-latest'

            self.model = genai.GenerativeModel(model_name_to_use)
            logger.info(f"Successfully configured Gemini API and initialized the model: '{model_name_to_use}'.")

        except Exception as e:
            # This will catch errors if 'gemini-1.5-flash-latest' is still problematic
            # (e.g., not found for v1beta, permissions, etc.)
            logger.error(f"Failed to initialize Gemini Service with model '{model_name_to_use}': {e}")
            self.model = None

    def generate_response(self, user_question: str, confluence_context: str) -> str:
        if not self.model:
            logger.error("Gemini model not initialized. Cannot generate response.")
            return "Error: The AI model is currently unavailable. Please try again later."

        # For logging, use the model name that was attempted during initialization.
        # If self.model exists, it means initialization with model_name_to_use (in __init__) was successful.
        # However, self.model object itself might not directly expose the "friendly name" like "gemini-1.5-flash-latest"
        # if it resolves to a more specific versioned name.
        # The log in __init__ is the most reliable for what was *intended*.
        # For this call log, it's okay to assume the intended model is what's active.

        prompt = f"""
Eres Conrad, un asistente virtual experto en la base de conocimientos de nuestra empresa almacenada en Confluence.
Un usuario ha preguntado: "{user_question}"

Basándote EXCLUSIVAMENTE en la siguiente información extraída de Confluence, por favor proporciona una respuesta clara y concisa.
Si la información no es suficiente para responder, indícalo amablemente.

Contexto de Confluence:
{confluence_context}

Respuesta:
"""

        logger.info(f"Sending prompt to Gemini (using configured model, intended: 'gemini-1.5-flash-latest'): {prompt[:200]}...")


        try:
            response = self.model.generate_content(prompt)

            if response and response.parts:
                generated_text = "".join(part.text for part in response.parts if hasattr(part, 'text'))
                logger.info("Successfully received response from Gemini.")
                return generated_text if generated_text else "No response text found."
            elif response and hasattr(response, 'prompt_feedback') and response.prompt_feedback:
                logger.warning(f"Gemini API call did not return content. Prompt Feedback: {response.prompt_feedback}")
                return f"Error: The request was blocked by the AI for the following reason: {response.prompt_feedback}"
            else:
                logger.warning(f"Gemini API call did not return any content or parts. Response: {response}")
                return "Error: No response was generated by the AI model."

        except Exception as e:
            logger.error(f"Error during Gemini API call: {e}")
            if hasattr(e, 'response') and e.response:
                 logger.error(f"Gemini API Error Response Details: {e.response}")
            return "Error: An unexpected issue occurred while trying to communicate with the AI model."

# Example Usage (for testing purposes)
if __name__ == "__main__":
    if not settings.GEMINI_API_KEY or "YOUR_GEMINI_API_KEY" in settings.GEMINI_API_KEY:
        print("Gemini API key not configured. Please set it in .env")
    else:
        gemini_service = GeminiService() # Model initialization logged here
        if gemini_service.model:
            print(f"GeminiService initialized (model intended: 'gemini-1.5-flash-latest').")
            test_question = "¿Cómo creo una página en Confluence?"
            test_context = "Context from 'Crear Páginas' (URL: example.com/crear, Relevance Score: 10):\nPara crear una página en Confluence, ve al espacio deseado, haz clic en el botón 'Crear' en la parte superior y selecciona 'Página'. Luego, puedes añadir un título y contenido.\n---"

            print(f"Testing Gemini with question: {test_question}")
            answer = gemini_service.generate_response(test_question, test_context)
            print(f"Gemini's Answer:\n{answer}")
        else:
            print("Could not initialize GeminiService. Check logs for errors.")
